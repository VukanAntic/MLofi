
@article{graves_generating_2013,
	title = {Generating Sequences With Recurrent Neural Networks},
	url = {https://arxiv.org/abs/1308.0850v5},
	abstract = {This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.},
	author = {Graves, Alex},
	date = {2013-08-04},
	langid = {english}},
}

@article{van_der_oord_wavenet_2016,
	title = {{WaveNet}: A Generative Model for Raw Audio},
	url = {http://arxiv.org/abs/1609.03499},
	shorttitle = {{WaveNet}},
	abstract = {This paper introduces {WaveNet}, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single {WaveNet} can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
	journaltitle = {{arXiv}:1609.03499 [cs]},
	author = {van der Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
	date = {2016-09-19},
	eprinttype = {arxiv},
	eprint = {1609.03499},
	keywords = {Computer Science - Machine Learning, Computer Science - Sound}},
}

@article{chung_empirical_2014,
	title = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
	url = {http://arxiv.org/abs/1412.3555},
	abstract = {In this paper we compare different types of recurrent units in recurrent neural networks ({RNNs}). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory ({LSTM}) unit and a recently proposed gated recurrent unit ({GRU}). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found {GRU} to be comparable to {LSTM}.},
	journaltitle = {{arXiv}:1412.3555 [cs]},
	author = {Chung, Junyoung and Gulcehre, Caglar and Cho, {KyungHyun} and Bengio, Yoshua},
	date = {2014-12-11},
	eprinttype = {arxiv},
	eprint = {1412.3555},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing}},
}